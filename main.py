import os
import pandas as pd
from io import BytesIO
from pyrogram import Client, filters, enums
from pyrogram.types import Message
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import asyncio
import logging
from get_stock_position import get_ma_position_data, get_ma_alignment_from_data, calculate_ma_scores
from dotenv import load_dotenv
import os
import time
from fastapi import FastAPI
import uvicorn
import os
from threading import Thread
import datetime
app_fastapi = FastAPI()

@app_fastapi.get("/")
async def root():
    return {"message": "è‚¡ç¥¨æ©Ÿå™¨äººæ´»è‘—å–”ï¼", "status": "running"}

async def run_web():
    """å•Ÿå‹• Uvicorn ä¼ºæœå™¨ï¼Œä¸¦ä½¿ç”¨ Server é¡è€Œé run å‡½å¼ä»¥é¿å…é˜»å¡"""
    port = int(os.environ.get("PORT", 10000))
    config = uvicorn.Config(app_fastapi, host="0.0.0.0", port=port, log_level="error")
    server = uvicorn.Server(config)
    
    # ä½¿ç”¨ await é‹è¡Œä¼ºæœå™¨ï¼Œå®ƒæœƒæŒçºŒé‹è¡Œä¸¦ç›£è½ Port
    print(f"FastAPI Web Service æ­£åœ¨ç›£è½ Port: {port}")
    await server.serve()


load_dotenv()

# ================== è¨­å®šå€ï¼ˆå…¨éƒ¨ç”¨ç’°å¢ƒè®Šæ•¸ï¼ŒRender ä¸Šè¶…å®‰å…¨ï¼‰==================
API_ID = int(os.getenv("API_ID"))           # Render å¾Œå°å¡«
API_HASH = os.getenv("API_HASH")            # Render å¾Œå°å¡«
BOT_TOKEN = os.getenv("BOT_TOKEN")          # Render å¾Œå°å¡«
MY_CHAT_ID = int(os.getenv("MY_CHAT_ID"))    # ä½ çš„ Telegram IDï¼Œä¾‹å¦‚ 1350443089
PETER_CHAT_ID = int(os.getenv("PETER_CHAT_ID"))    # ä½ çš„ Telegram IDï¼Œä¾‹å¦‚ 1350443089
PORT = int(os.getenv("PORT")) 

# å…¨åŸŸå„²å­˜æœ€æ–°çš„ DataFrame
latest_df: pd.DataFrame | None = None

# å»ºç«‹ Pyrogram å®¢æˆ¶ç«¯
app = Client(
    "my_stock_bot",
    api_id=API_ID,
    api_hash=API_HASH,
    bot_token=BOT_TOKEN,
    port=PORT
)


# ==================== åŠ ä¸Šé€™æ®µï¼šæ–‡å­—æŒ‡ä»¤è§¸ç™¼æ›´æ–° ====================
@app.on_message(filters.private & filters.text)
async def manual_trigger(client: Client, message: Message):
    """åªè¦ä½ å‚³ã€Œupdateã€å°±ç«‹åˆ»åŸ·è¡Œä¸€æ¬¡ daily_job"""
    if message.text.strip().lower() in ["update", "æ›´æ–°", "è·‘ä¸€æ¬¡", "åŸ·è¡Œ"]:
        await message.reply("æ”¶åˆ°æŒ‡ä»¤ï¼Œæ­£åœ¨åŸ·è¡Œæ¯æ—¥é€šçŸ¥...")
        await daily_job()
        # å¦‚æœä½ æœ‰ã€Œå‰ä¸€å¤©ã€ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥åŠ å¦ä¸€å€‹æŒ‡ä»¤
        # elif message.text.strip().lower() == "prev":
        #     await daily_job(is_previous_day=True, triggered_by_user=True, chat_id=message.chat.id)
# ================== æ”¶åˆ° Excel æ™‚è‡ªå‹•æ›´æ–° ==================
@app.on_message(filters.private & filters.document)
async def receive_excel(client: Client, message: Message):
    global latest_df
    if message.document.file_name and message.document.file_name.lower().endswith(('.xlsx', '.xls')):
        await message.reply("æ”¶åˆ° Excelï¼Œæ­£åœ¨è®€å–...")
        file = await message.download(in_memory=True)
        try:
            latest_df = pd.read_excel(BytesIO(file.getbuffer()))
            rows = len(latest_df)
            cols = len(latest_df.columns)
            await message.reply(f"Excel æ›´æ–°æˆåŠŸï¼\nå…± {rows} ç­†è³‡æ–™ï¼Œ{cols} å€‹æ¬„ä½")
            logging.info(f"Excel å·²æ›´æ–°ï¼Œ{rows} è¡Œ")
        except Exception as e:
            await message.reply(f"è®€å–å¤±æ•—ï¼š{str(e)}")
            logging.error(f"è®€ Excel å¤±æ•—: {e}")

# ----------------------------------------------------
# 2. æ–°å¢è¨Šæ¯è™•ç†å‡½å¼ï¼šè™•ç†ç”¨æˆ¶è¼¸å…¥çš„è‚¡ç¥¨ä»£è™Ÿ/åç¨±
# ----------------------------------------------------
@app.on_message(filters.private & filters.text & ~filters.command) # æ¥æ”¶ç§èŠä¸­çš„æ–‡å­—è¨Šæ¯ï¼Œæ’é™¤æŒ‡ä»¤
async def handle_stock_query(client: Client, message: Message):
    global latest_df
    query = message.text.strip().upper() # è½‰æ›æˆå¤§å¯«æ–¹ä¾¿æ¯”å°

    if latest_df is None or latest_df.empty:
        await message.reply("ç›®å‰ Excel è³‡æ–™ç‚ºç©ºï¼Œè«‹å…ˆä¸Šå‚³æª”æ¡ˆã€‚")
        return

    # åˆ¤æ–·è¼¸å…¥æ˜¯å¦ç‚ºç´”æ•¸å­—çš„è‚¡ç¥¨ä»£è™Ÿï¼ˆä¾‹å¦‚ï¼š2330, 2454ï¼‰
    is_ticker_query = query.isdigit()
    
    # æ ¹æ“šè‚¡ç¥¨ä»£è™Ÿæˆ–å…¬å¸åç¨±ä¾†éæ¿¾è³‡æ–™
    if is_ticker_query:
        # è‚¡ç¥¨ä»£è™Ÿæ¯”å°
        matched_rows = latest_df[latest_df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.strip() == query]
    else:
        # å…¬å¸åç¨±åŒ…å«æ¯”å°
        matched_rows = latest_df[latest_df['å…¬å¸åç¨±'].astype(str).str.contains(query, case=False, na=False)]

    if matched_rows.empty:
        await message.reply(f"æ‰¾ä¸åˆ°é—œæ–¼ã€Œ**{query}**ã€çš„è³‡æ–™ã€‚")
        return

    await message.reply(f"æ‰¾åˆ° {len(matched_rows)} ç­†é—œæ–¼ã€Œ**{query}**ã€çš„å ±å‘Šï¼Œæ­£åœ¨æ•´ç†...")

    # å°‡åŒ¹é…åˆ°çš„ DataFrame è½‰æ›æˆé¡ä¼¼ daily_job ä¸­ results çš„æ ¼å¼
    # ç”±æ–¼é€™è£¡åªåšæœå°‹ï¼Œæˆ‘å€‘å…ˆå‡è¨­ç”¨æˆ¶è¼¸å…¥çš„è‚¡ç¥¨å·²æ»¿è¶³æˆé•·ç‡æ¢ä»¶ï¼Œ
    # ä½†ç‚ºäº†è®“å¾ŒçºŒçš„ filter_and_deduplicate_results æ­£å¸¸é‹ä½œï¼Œ
    # é€™è£¡éœ€è¦**æ¨¡æ“¬** daily_job å®Œæ•´çš„è™•ç†æµç¨‹ (é€™éƒ¨åˆ†éœ€è¦æ‚¨è£œé½Šç¼ºå¤±çš„å‡½å¼)
    
    # *** æ³¨æ„ï¼šç‚ºäº†ä½¿ç”¨ MA ç¯©é¸é‚è¼¯ï¼Œæˆ‘å€‘å¿…é ˆç¢ºä¿æ‰€æœ‰æ¬„ä½éƒ½å·²è¨ˆç®—ï¼Œ
    # *** é€™è£¡æ¡ç”¨ä¸€å€‹ç°¡åŒ–æ–¹å¼ï¼Œç›´æ¥å° matched_rows é€²è¡Œå»é‡å’Œè³‡è¨Šæå–
    
    temp_results = []
    
    # é€™è£¡éœ€è¦æ‚¨å°‡ daily_job è¿´åœˆä¸­ï¼Œç²å– MA è³‡è¨Šå’Œè¨ˆç®—åˆ†æ•¸çš„é‚è¼¯è¤‡è£½åˆ°é€™è£¡ï¼Œ
    # æ‰èƒ½ç¢ºä¿ r.get('MAè²·é»åˆ†æ•¸', 0) ç­‰éµæ˜¯å­˜åœ¨çš„ã€‚
    # ç”±æ–¼é€™äº›å‡½å¼ (get_ma_position_data, get_ma_alignment_from_data, calculate_ma_scores)
    # ä¸åœ¨æä¾›çš„ç¨‹å¼ç¢¼ä¸­ï¼Œæˆ‘å€‘å‡è¨­æ‚¨æœƒè£œä¸Šï¼Œé€™è£¡åªå¯«æ ¸å¿ƒé‚è¼¯ã€‚
    
    for idx, row in matched_rows.iterrows():
        try:
            ticker = str(row['è‚¡ç¥¨ä»£è™Ÿ']).strip()
            name = str(row['å…¬å¸åç¨±']).strip()
            broker = str(row['åˆ¸å•†']).strip()
            date = str(row['æ—¥æœŸ']).strip()
            growth_25 = float(row['EPS25æˆé•·ç‡(%)'])
            growth_26 = float(row['EPS26æˆé•·ç‡(%)'])
            growth_27 = float(row['EPS27æˆé•·ç‡(%)'])
            target = str(row['ç›®æ¨™åƒ¹']).strip()
            abstract = str(row['å ±å‘Šæ‘˜è¦']).strip()
            
            # --- æ¨¡æ“¬ growth_values å’Œ valid_count çš„è¨ˆç®— (ç”¨æ–¼é¡¯ç¤º) ---
            # --- æ¨¡æ“¬ MA è³‡è¨Šç²å–ï¼ˆé‡è¦ï¼šé€™è£¡éœ€è¦æ‚¨ç¢ºä¿é€™éƒ¨åˆ†èƒ½é‹è¡Œï¼‰ ---
            ma_data = get_ma_position_data(ticker, period="max")
            stock_status = get_ma_alignment_from_data(ma_data, consolidation_threshold=0.02)
            ma_scores = calculate_ma_scores(ma_data)

            result = {
                "ä»£è™Ÿ": ticker,
                "åç¨±": name,
                "ç›®æ¨™åƒ¹": target,
                "26æˆé•·ç‡": growth_26,
                "è¶¨å‹¢":stock_status,
                **ma_scores,
                "å ±å‘Šæ‘˜è¦":abstract,
                "æ—¥æœŸ": date,
                "åˆ¸å•†":broker,
            }
            temp_results.append(result)
        except Exception as e:
            logging.error(f"å–®ç¨æŸ¥è©¢ {ticker} è™•ç†å¤±æ•—: {e}")
            continue

    # æ­¥é©Ÿ 3ï¼šä½¿ç”¨å»é‡å‡½å¼ï¼Œåªä¿ç•™ (ä»£è™Ÿ, åˆ¸å•†) çµ„åˆä¸­æ—¥æœŸæœ€æ–°çš„é‚£ä¸€ç­†
    # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘**ä¸**å†å¼·åˆ¶è¦æ±‚ MAè²·é»åˆ†æ•¸ > 5ï¼Œè€Œæ˜¯**ä¿ç•™æ‰€æœ‰æ‰¾åˆ°çš„æœ€æ–°å ±å‘Š**
    # å¦å‰‡ï¼Œå¦‚æœç”¨æˆ¶å–®ç¨æŸ¥è©¢ï¼Œä½†åˆ†æ•¸ä¸å¤ ï¼Œä»–æœƒå¾—ä¸åˆ°ä»»ä½•è³‡è¨Šã€‚
    # å¦‚æœæ‚¨å …æŒå–®ç¨æŸ¥è©¢ä¹Ÿå¿…é ˆ MAè²·é»åˆ†æ•¸ > 5ï¼Œè«‹æ”¹ç”¨ filter_and_deduplicate_results

    final_results = filter_and_deduplicate_results(temp_results)

            
    # final_query_results = [item['data'] for item in unique_latest_results.values()]


    # æ­¥é©Ÿ 4ï¼šæ ¼å¼åŒ–è¼¸å‡ºçµæœ
    if not final_results:
        await message.reply(f"æ‰¾åˆ°é—œæ–¼ã€Œ**{query}**ã€çš„å ±å‘Šï¼Œä½†è™•ç†å¾Œæ²’æœ‰æœ‰æ•ˆçš„æœ€æ–°è³‡æ–™å¯é¡¯ç¤ºã€‚")
        return
        
    response_text = f"**ğŸ” æ‰¾åˆ°é—œæ–¼ã€Œ{query}ã€çš„æœ€æ–°å ±å‘Šï¼š**\n\n"
    
    # æ ¹æ“š MA è²·é»åˆ†æ•¸é™åºæ’åºï¼Œåˆ†æ•¸é«˜çš„å…ˆé¡¯ç¤º
    # final_results.sort(key=lambda x: x.get('MAè²·é»åˆ†æ•¸', 0), reverse=True)

    for r in final_results:
        stock_code = r['ä»£è™Ÿ']
        stock_name = r['åç¨±']
        stock_link = f"https://tw.stock.yahoo.com/quote/{stock_code}.TW/technical-analysis"
        

        response_text += (f"**<code>{stock_code}</code> {stock_name}**\n"
                          f" Â â”œ **ç›®æ¨™åƒ¹ï¼š** {r['ç›®æ¨™åƒ¹']}\n"
                          f" Â â”œ **åˆ¸å•†ï¼š** {r['åˆ¸å•†']} (å ±å‘Šæ—¥æœŸ: {r['æ—¥æœŸ']})\n"
                          f" Â â”œ **MA è²·é»åˆ†æ•¸ï¼š** `{r.get('MAè²·é»åˆ†æ•¸', 0):.0f}` (é ˆ > 5)\n"
                          f" Â â”œ **Kç·šè¶¨å‹¢ï¼š** {r['è¶¨å‹¢']}\n"
                          f" Â â”œ **åé›¢åº¦(240/60/20)ï¼š** {r['D240']:.2f}% / {r['D60']:.2f}% / {r['D20']:.2f}%\n"
                          f" Â â”œ **å ±å‘Šæ‘˜è¦ï¼š** `{r['å ±å‘Šæ‘˜è¦']}`\n"
                          f" Â â”” **æŠ€è¡“åˆ†æï¼š** <a href='{stock_link}'>é»æ­¤æŸ¥çœ‹ K ç·š</a>\n\n"
                          )

    await message.reply(
        response_text,
        parse_mode=enums.ParseMode.HTML,
        disable_web_page_preview=True
    )
    logging.info(f"å·²å›è¦†ç”¨æˆ¶æŸ¥è©¢: {query}")

def filter_and_deduplicate_results(results_list: list) -> list:
    """
    å°çµæœåˆ—è¡¨é€²è¡Œå»é‡ï¼ˆåŒè‚¡ç¥¨ä»£è™Ÿ+åŒåˆ¸å•†åªä¿ç•™æ—¥æœŸæœ€æ–°çš„ä¸€ç­†ï¼‰
    ä¸¦ç¯©é¸å‡º MAè²·é»åˆ†æ•¸ > 5 çš„çµæœã€‚
    """
    # æ­¥é©Ÿ 1ï¼šç¯©é¸ MA è²·é»åˆ†æ•¸ > 5
    filtered_results = [r for r in results_list if r.get('MAè²·é»åˆ†æ•¸', 0) > 5]
    
    unique_results = {}
    for r in filtered_results:
        # ä½¿ç”¨ 'ä»£è™Ÿ' å’Œ 'åˆ¸å•†' ä½œç‚ºå”¯ä¸€çš„ Key
        key = (r.get('ä»£è™Ÿ'), r.get('åˆ¸å•†'))
        # é€™è£¡éœ€è¦å¾ Excel è®€å–æ™‚ï¼Œç¢ºä¿ 'æ—¥æœŸ' æ¬„ä½æœ‰æ­£ç¢ºå„²å­˜
        # ç”±æ–¼æ‚¨åœ¨ daily_job è£¡å°‡ Excel çš„ 'æ—¥æœŸ' æ¬„ä½å­˜å…¥ r['æ—¥æœŸ']
        current_date_str = r.get('æ—¥æœŸ', '1970/01/01 00:00:00 AM')

        # å˜—è©¦å°‡æ—¥æœŸå­—ä¸²è½‰æ›ç‚º datetime ç‰©ä»¶é€²è¡Œæ¯”è¼ƒ
        try:
            # æ ¹æ“šæ‚¨çš„ç¯„ä¾‹æ—¥æœŸæ ¼å¼ '2025/11/12 12:00:00 AM'
            # é€™è£¡å‡è¨­ r['æ—¥æœŸ'] å·²ç¶“åŒ…å«äº†æ­£ç¢ºçš„æ—¥æœŸå­—ä¸²
            current_date = datetime.strptime(current_date_str, '%Y/%m/%d %I:%M:%S %p')
        except ValueError:
            current_date = datetime.min
            
        # æª¢æŸ¥é€™å€‹çµ„åˆæ˜¯å¦å·²å­˜åœ¨ï¼Œæˆ–ç•¶å‰çš„æ—¥æœŸæ˜¯å¦æ›´æ–°
        if key not in unique_results or current_date > unique_results[key]['date_obj']:
            unique_results[key] = {
                'data': r,
                'date_obj': current_date
            }
            
    # å°‡è™•ç†éå¾Œï¼Œåªä¿ç•™æœ€æ–°æ—¥æœŸçš„è¨˜éŒ„çš„å­—å…¸è½‰æ›å›åˆ—è¡¨
    final_results = [item['data'] for item in unique_results.values()]
    return final_results

# ================== æ¯æ—¥å®šæ™‚ç™¼é€é€šçŸ¥ ==================
async def daily_job():
    global latest_df
    if latest_df is None or latest_df.empty:
        text = "ä»Šæ—¥é€šçŸ¥\nç›®å‰é‚„æ²’æœ‰æ”¶åˆ° Excel æª”æ¡ˆï¼Œè«‹å‚³çµ¦æˆ‘ï½"
        await app.send_message(MY_CHAT_ID, text)
        await app.send_message(PETER_CHAT_ID, text)
        return

    results = []

    # å–å¾— Excel å…¨éƒ¨æ¬„ä½åç¨±ï¼ˆä¿ç•™çµ¦ä½ å¾Œé¢ç”¨ï¼‰
    all_columns = latest_df.columns.tolist()
    tt = f"Excel æ¬„ä½ç¸½å…± {len(all_columns)} å€‹ï¼š{all_columns}"
    # await app.send_message(MY_CHAT_ID, tt)
    print(f"Excel æ¬„ä½ç¸½å…± {len(all_columns)} å€‹ï¼š{all_columns}")

    # å¿…è¦æ¬„ä½æª¢æŸ¥ï¼ˆåªæª¢æŸ¥æœ€æ ¸å¿ƒçš„ï¼Œå…¶ä»–æœ‰ç¼ºå°±è·³éé‚£æª”ï¼‰
    if 'è‚¡ç¥¨ä»£è™Ÿ' not in latest_df.columns or 'å…¬å¸åç¨±' not in latest_df.columns:
        await app.send_message(MY_CHAT_ID, "Excel ç¼ºå°‘ã€Œè‚¡ç¥¨ä»£è™Ÿã€æˆ–ã€Œå…¬å¸åç¨±ã€æ¬„ä½")
        await app.send_message(PETER_CHAT_ID, "Excel ç¼ºå°‘ã€Œè‚¡ç¥¨ä»£è™Ÿã€æˆ–ã€Œå…¬å¸åç¨±ã€æ¬„ä½")
        return
    
    for idx, row in latest_df.iterrows():
        ticker = str(row['è‚¡ç¥¨ä»£è™Ÿ']).strip()
        name   = str(row['å…¬å¸åç¨±']).strip()
        broker   = str(row['åˆ¸å•†']).strip()
        date = str(row['æ—¥æœŸ']).strip()
        target = str(row['ç›®æ¨™åƒ¹']).strip()
        # abstract = str(row['å ±å‘Šæ‘˜è¦']).strip()
        # await app.send_message(MY_CHAT_ID, ticker)
        # === æ¢ä»¶ 1ï¼š26æˆé•·ç‡ > 15% ===
        try:
            growth_26 = float(row['EPS26æˆé•·ç‡(%)'])
            if growth_26 <= 15:
                continue
        except:
            continue  # è½‰æ›å¤±æ•—å°±è·³é
        print(ticker)
        # # === æ¢ä»¶ 2ï¼šEPS25æˆé•·ç‡(%)ã€EPS26æˆé•·ç‡(%)ã€EPS27æˆé•·ç‡(%) éƒ½ > 0 ===
        growth_cols = ['EPS25æˆé•·ç‡(%)', 'EPS26æˆé•·ç‡(%)', 'EPS27æˆé•·ç‡(%)']
        growth_values = []
        valid_count = 0

        if idx % 5 == 0 and idx != 0: # ä¾‹å¦‚ï¼šæ¯è™•ç† 10 æª”è‚¡ç¥¨ï¼Œæš«åœ 2 ç§’
             print("--- æš«åœ 3 ç§’ï¼Œé¿å…é »ç¹æŸ¥åƒ¹è¢«é–å®š ---")
             time.sleep(3)

        for col in growth_cols:
            if col not in row or pd.isna(row[col]) or row[col] == '':
                continue  # ç©ºå€¼ç›´æ¥è·³éï¼Œä¸ä¸­æ–·
            try:
                val = float(row[col])
                if val > 0:
                    valid_count += 1
                growth_values.append(val)
            except:
                continue

        # è‡³å°‘è¦æœ‰ 1 å€‹ >0 æ‰ç®—ï¼ˆä½ èªªã€Œéƒ½>0ã€ï¼Œä½†è‹¥æœ‰ç¼ºå€¼åªçœ‹æœ‰è³‡æ–™çš„ï¼‰
        # å¦‚æœä½ åš´æ ¼è¦æ±‚ã€Œæœ‰å¡«çš„æ¬„ä½å…¨éƒ¨å¿…é ˆ >0ã€ï¼Œæ”¹æˆä¸‹é¢é€™è¡Œï¼š
        if valid_count == 0 or valid_count < len([v for v in growth_values if not pd.isna(v)]):
            continue

        # === å…©æ¢ä»¶éƒ½é€šéï¼Œé–‹å§‹è¨ˆç®— MA ä½ç½® ===
        try:
            print(f"æ­£åœ¨åˆ†æ {ticker} {name}...")
            ma_data = get_ma_position_data(ticker, period="max")
            stock_status = get_ma_alignment_from_data(ma_data, consolidation_threshold=0.02)
            ma_scores = calculate_ma_scores(ma_data)
            result = {
                "ä»£è™Ÿ": ticker,
                "åç¨±": name,
                "ç›®æ¨™åƒ¹": target,
                "26æˆé•·ç‡": growth_26,
                # "EPSæˆé•·ç‡æ­£å‘æ•¸": valid_count,
                "æˆé•·ç‡æ˜ç´°": growth_values,
                "è¶¨å‹¢":stock_status,
                **ma_scores,  # å±•é–‹åˆ†æ•¸èˆ‡åé›¢åº¦è³‡æ–™
                "æ—¥æœŸ": date,
                "åˆ¸å•†":broker,
            }
            results.append(result)
            print(f"åŠ å…¥æ¸…å–®ï¼š{ticker} {name}")

        except Exception as e:
            print(f"{ticker} è¨ˆç®—å¤±æ•—: {e}")

    results.sort(key=lambda x: x.get('MAè²·é»åˆ†æ•¸', 0), reverse=True)
    filtered_results = [r for r in results if r.get('MAè²·é»åˆ†æ•¸', 0) > 5]

    
    final_results = filter_and_deduplicate_results(filtered_results)
    # === ç”¢ç”Ÿæœ€çµ‚é€šçŸ¥ ===
    if not final_results:
        text = ("ä»Šæ—¥æƒæå®Œæˆ\n"
                "æ²’æœ‰è‚¡ç¥¨åŒæ™‚æ»¿è¶³ï¼š\n"
                "â€¢ 26æˆé•·ç‡ > 15%\n"
                "â€¢ EPSè¿‘ä¸‰å¹´æˆé•·ç‡(%) æœ‰å¡«çš„æ¬„ä½çš† > 0%")
    else:
        text = f"æ‰¾åˆ° {len(final_results)} ä½ç½®ä¸éŒ¯çš„è‚¡ç¥¨ï¼\n\n"
        for r in final_results:
            stock_code = r['ä»£è™Ÿ']
            stock_link = f"https://tw.stock.yahoo.com/quote/{stock_code}.TW/technical-analysis"
            text += (f"â€¢ <code>{r['ä»£è™Ÿ']}</code> {r['åç¨±']}\n"
                     f"  â”œ ç›®æ¨™åƒ¹ï¼š{r['ç›®æ¨™åƒ¹']}\n"
                     f"  â”œ 26æˆé•·ç‡ï¼š{r['26æˆé•·ç‡']:.1f}%\n"
                    #  f"  â”œ é€£çºŒ3 å¹´EPSæ­£æˆé•·ï¼š{r['EPSæˆé•·ç‡æ­£å‘æ•¸']}\n"
                     f"  â”œ kç·šè¶¨å‹¢ï¼š{r['è¶¨å‹¢']}\n"
                     f"  â”œ D240/D60/D20 åé›¢åº¦ï¼š{r['D240']:.2f}% / {r['D60']:.2f}% / {r['D20']:.2f}%\n\n"
                     f"  â”œ Kç·šï¼š**<a href='{stock_link}'><code>{stock_code}</code> {r['åç¨±']}</a>**\n"                     
                     f"  â”” åˆ¸å•†ï¼š{r['åˆ¸å•†']}\n"
                    )

        text += f"æ›´æ–°æ™‚é–“ï¼š{pd.Timestamp('now').tz_localize('Asia/Taipei').strftime('%Y-%m-%d %H:%M')}"

    await app.send_message(
        MY_CHAT_ID, 
        text, 
        parse_mode=enums.ParseMode.HTML, # <--- å°‡å­—ä¸²æ›¿æ›ç‚º enums.ParseMode.HTML
        disable_web_page_preview=True
    )
    await app.send_message(
        PETER_CHAT_ID, 
        text, 
        parse_mode=enums.ParseMode.HTML, # <--- å°‡å­—ä¸²æ›¿æ›ç‚º enums.ParseMode.HTML
        disable_web_page_preview=True
    )
    print(f"é€šçŸ¥å·²ç™¼é€ï¼Œå…± {len(results)} æª”ç¬¦åˆæ¢ä»¶")

    

# ================== ä¸»ç¨‹å¼å•Ÿå‹• ==================
async def main():
    print("è‚¡ç¥¨æ©Ÿå™¨äººå•Ÿå‹•ä¸­...")
    await app.start()
    print("æ©Ÿå™¨äººä¸Šç·šï¼å¯ä»¥é–‹å§‹å‚³ Excel çµ¦æˆ‘äº†")

    # è¨­å®šå®šæ™‚ä»»å‹™ï¼ˆå°ç£æ™‚é–“æ¯å¤©ä¸­åˆ12:00 + æ™šä¸Š10:00ï¼‰
    scheduler = AsyncIOScheduler(timezone="Asia/Taipei")
    scheduler.add_job(daily_job, "cron", hour=12, minute=0)
    scheduler.add_job(daily_job, "cron", hour=22, minute=0)
    scheduler.start()

    print("æ’ç¨‹å·²å•Ÿå‹•ï¼šæ¯å¤© 12:00 å’Œ 22:00 ç™¼é€é€šçŸ¥")
    # ä¿æŒé‹è¡Œ
    await asyncio.gather(
        run_web(),       # å•Ÿå‹• Web æœå‹™ä¸¦ç›£è½ Port
        asyncio.Event().wait() # è®“ä¸»ç¨‹åºç­‰å¾…ï¼Œä¿æŒ Pyrogram Bot é‹è¡Œ
    )

# if __name__ == "__main__":
    # Render æœƒè‡ªå‹•åŸ·è¡Œé€™å€‹
    # app.run(main())
    # Thread(target=run_web, daemon=True).start()

if __name__ == "__main__":
    # ã€ä½¿ç”¨ Pyrogram çš„ app.run() ä¾†é‹è¡Œä¸»ç¨‹åºã€‘
    # é€™æ˜¯ Pyrogram Bot çš„æ¨™æº–å•Ÿå‹•æ–¹å¼
    app.run(main()) # é€™è¡Œç¢ºä¿ main() å‡½æ•¸è¢«æ­£ç¢ºåŸ·è¡Œä¸¦é˜»å¡